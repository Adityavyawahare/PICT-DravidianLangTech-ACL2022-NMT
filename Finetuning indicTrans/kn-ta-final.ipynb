{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# create a seperate folder to store everything\n!mkdir finetuning\n%cd finetuning","metadata":{"id":"rE4MO-8bDtwD","outputId":"8fbfc9c8-2c6c-40e1-f32b-cceff83749c0","execution":{"iopub.status.busy":"2022-02-09T13:54:28.058704Z","iopub.execute_input":"2022-02-09T13:54:28.059086Z","iopub.status.idle":"2022-02-09T13:54:28.752852Z","shell.execute_reply.started":"2022-02-09T13:54:28.059007Z","shell.execute_reply":"2022-02-09T13:54:28.752014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clone the repo for running finetuning\n!git clone https://github.com/AI4Bharat/indicTrans.git\n%cd indicTrans\n# clone requirements repositories\n!git clone https://github.com/anoopkunchukuttan/indic_nlp_library.git\n!git clone https://github.com/anoopkunchukuttan/indic_nlp_resources.git\n!git clone https://github.com/rsennrich/subword-nmt.git\n%cd ..","metadata":{"id":"-2Rs6_WkD_gF","outputId":"11d8e60a-fb7f-4293-ea11-f4f84330f226","execution":{"iopub.status.busy":"2022-02-09T13:54:28.754702Z","iopub.execute_input":"2022-02-09T13:54:28.755196Z","iopub.status.idle":"2022-02-09T13:54:39.933377Z","shell.execute_reply.started":"2022-02-09T13:54:28.755151Z","shell.execute_reply":"2022-02-09T13:54:39.932104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:54:39.934907Z","iopub.execute_input":"2022-02-09T13:54:39.935371Z","iopub.status.idle":"2022-02-09T13:54:40.603404Z","shell.execute_reply.started":"2022-02-09T13:54:39.935331Z","shell.execute_reply":"2022-02-09T13:54:40.602587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! sudo apt install tree\n\n# Install the necessary libraries\n!pip install sacremoses pandas mock sacrebleu tensorboardX pyarrow indic-nlp-library\n! pip install wandb\n# Install fairseq from source\n!git clone https://github.com/pytorch/fairseq.git\n%cd fairseq\n# !git checkout da9eaba12d82b9bfc1442f0e2c6fc1b895f4d35d\n!pip install --editable ./\n%cd ..","metadata":{"id":"duwTvJ9xEBJ1","outputId":"e259d1f7-7bd7-4119-8f89-46c117fd7a1c","execution":{"iopub.status.busy":"2022-02-09T13:54:40.605808Z","iopub.execute_input":"2022-02-09T13:54:40.606165Z","iopub.status.idle":"2022-02-09T13:56:05.218239Z","shell.execute_reply.started":"2022-02-09T13:54:40.606126Z","shell.execute_reply":"2022-02-09T13:56:05.217440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n# This is secret and shouldn't be checked into version control\nWANDB_API_KEY='c32fbee4e85afebf8006826b6f255e9421a35085'\n# Name and notes optional\n\nwandb.login(key=WANDB_API_KEY)\nwandb.init(project=\"kn-te\", entity=\"adityavyawahare\")\n# # login authorization.","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:56:05.220119Z","iopub.execute_input":"2022-02-09T13:56:05.220396Z","iopub.status.idle":"2022-02-09T13:56:13.023847Z","shell.execute_reply.started":"2022-02-09T13:56:05.220359Z","shell.execute_reply":"2022-02-09T13:56:13.023123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls\n","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:56:13.025634Z","iopub.execute_input":"2022-02-09T13:56:13.025898Z","iopub.status.idle":"2022-02-09T13:56:13.698388Z","shell.execute_reply.started":"2022-02-09T13:56:13.025862Z","shell.execute_reply":"2022-02-09T13:56:13.697555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install -U --no-cache-dir gdown --pre","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:56:13.700310Z","iopub.execute_input":"2022-02-09T13:56:13.700893Z","iopub.status.idle":"2022-02-09T13:56:32.204948Z","shell.execute_reply.started":"2022-02-09T13:56:13.700852Z","shell.execute_reply":"2022-02-09T13:56:32.204071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..\n!mkdir drive\n%cd drive\n!mkdir MyDrive\n%cd MyDrive\n!mkdir Dravidian_Dataset_Full\n%cd Dravidian_Dataset_Full","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:56:32.206312Z","iopub.execute_input":"2022-02-09T13:56:32.206571Z","iopub.status.idle":"2022-02-09T13:56:34.224067Z","shell.execute_reply.started":"2022-02-09T13:56:32.206535Z","shell.execute_reply":"2022-02-09T13:56:34.223270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 12RI9PzWR0c3fR83j2f2VG5yhwvDKMKrf --folder","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:56:34.226030Z","iopub.execute_input":"2022-02-09T13:56:34.226346Z","iopub.status.idle":"2022-02-09T13:57:13.409726Z","shell.execute_reply.started":"2022-02-09T13:56:34.226305Z","shell.execute_reply":"2022-02-09T13:57:13.408889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 11o3czc-T8sVr_h_2YxQOroaOnWcFzZ-9--folder\n# !gdown --id 1Pz3oFKy6VpQVL0Bbi3B0mCUZOIkIIXeC --folder","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:57:13.413431Z","iopub.execute_input":"2022-02-09T13:57:13.413642Z","iopub.status.idle":"2022-02-09T13:57:32.018663Z","shell.execute_reply.started":"2022-02-09T13:57:13.413616Z","shell.execute_reply":"2022-02-09T13:57:32.017860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 12JMZrf35C8Uc9uWgqGsrAFp2CI6EvcU9 --folder #backtranslation","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:57:32.021780Z","iopub.execute_input":"2022-02-09T13:57:32.021989Z","iopub.status.idle":"2022-02-09T13:57:45.207382Z","shell.execute_reply.started":"2022-02-09T13:57:32.021963Z","shell.execute_reply":"2022-02-09T13:57:45.206558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 109_Hl10D9x7TcprsR5cV3MTuKNkDYH0A --folder","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:57:45.208949Z","iopub.execute_input":"2022-02-09T13:57:45.209624Z","iopub.status.idle":"2022-02-09T13:57:54.446176Z","shell.execute_reply.started":"2022-02-09T13:57:45.209585Z","shell.execute_reply":"2022-02-09T13:57:54.445185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:57:54.447657Z","iopub.execute_input":"2022-02-09T13:57:54.448196Z","iopub.status.idle":"2022-02-09T13:57:55.125532Z","shell.execute_reply.started":"2022-02-09T13:57:54.448150Z","shell.execute_reply":"2022-02-09T13:57:55.124681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ../../../finetuning/indicTrans","metadata":{"id":"XkWONCdr-8EU","outputId":"6e6b159a-ca8b-4aab-ead8-4c1fc192dd54","execution":{"iopub.status.busy":"2022-02-09T13:57:55.127154Z","iopub.execute_input":"2022-02-09T13:57:55.127447Z","iopub.status.idle":"2022-02-09T13:57:55.136063Z","shell.execute_reply.started":"2022-02-09T13:57:55.127411Z","shell.execute_reply":"2022-02-09T13:57:55.135289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env JOBLIB_TEMP_FOLDER=/tmp","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:57:55.137830Z","iopub.execute_input":"2022-02-09T13:57:55.138827Z","iopub.status.idle":"2022-02-09T13:57:55.149284Z","shell.execute_reply.started":"2022-02-09T13:57:55.138754Z","shell.execute_reply":"2022-02-09T13:57:55.148480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:57:55.150649Z","iopub.execute_input":"2022-02-09T13:57:55.151643Z","iopub.status.idle":"2022-02-09T13:57:55.832719Z","shell.execute_reply.started":"2022-02-09T13:57:55.151602Z","shell.execute_reply":"2022-02-09T13:57:55.831784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finetuning the model\n\n# pls refer to fairseq documentaion to know more about each of these options (https://fairseq.readthedocs.io/en/latest/command_line_tools.html)\n\n\n# some notable args:\n# --max-update=1000     -> for this example, to demonstrate how to finetune we are only training for 1000 steps. You should increase this when finetuning\n# --arch=transformer_4x -> we use a custom transformer model and name it transformer_4x (4 times the parameter size of transformer  base)\n# --user_dir            -> we define the custom transformer arch in model_configs folder and pass it as an argument to user_dir for fairseq to register this architechture\n# --lr                  -> learning rate. From our limited experiments, we find that lower learning rates like 3e-5 works best for finetuning.\n# --restore-file        -> reload the pretrained checkpoint and start training from here (change this path for indic-en. Currently its is set to en-indic)\n# --reset-*             -> reset and not use lr scheduler, dataloader, optimizer etc of the older checkpoint\n# --max_tokns           -> this is max tokens per batch\n\n\n!( fairseq-train ../../drive/MyDrive/Dravidian_Dataset_Full/mono_final_bin \\\n--max-source-positions=1320 \\\n--max-target-positions=1320 \\\n--max-epoch=3 \\\n--share-all-embeddings \\\n--arch=transformer_4x \\\n--criterion=label_smoothed_cross_entropy \\\n--source-lang=SRC \\\n--target-lang=TGT \\\n--label-smoothing=0.1 \\\n--optimizer adam \\\n--adam-betas \"(0.9, 0.98)\" \\\n--clip-norm 1.0 \\\n--warmup-init-lr 1e-07 \\\n--warmup-updates 1000 \\\n--dropout 0.2 \\\n--lr-scheduler=inverse_sqrt \\\n--lr 3e-5 \\\n--tensorboard-logdir ../../../tmp/tensorboard-wandb \\\n--save-dir ../../drive/MyDrive/Dravidian_Dataset_Full/model \\\n--skip-invalid-size-inputs-valid-test \\\n--fp16 \\\n--user-dir model_configs \\\n--update-freq=2 \\\n--distributed-world-size 1 \\\n--max-tokens 1568 \\\n--eval-bleu \\\n--eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n--eval-bleu-detok moses \\\n--eval-bleu-remove-bpe \\\n--eval-bleu-print-samples \\\n--best-checkpoint-metric bleu \\\n--maximize-best-checkpoint-metric \\\n--no-epoch-checkpoints \\\n--restore-file ../../drive/MyDrive/Dravidian_Dataset_Full/model/checkpoint_best.pt \\\n--wandb-project \"kn-ta backtranslation_strip final pls\" \\\n--reset-lr-scheduler \\\n--reset-meters \\\n--reset-dataloader \\\n--reset-optimizer)","metadata":{"id":"iz6tzbe2tcs7","outputId":"213b412a-68f3-4c5a-f229-1947bef279a0","execution":{"iopub.status.busy":"2022-02-09T13:57:55.836128Z","iopub.execute_input":"2022-02-09T13:57:55.836381Z","iopub.status.idle":"2022-02-09T15:17:39.270283Z","shell.execute_reply.started":"2022-02-09T13:57:55.836353Z","shell.execute_reply":"2022-02-09T15:17:39.269276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finetuning the model\n\n# pls refer to fairseq documentaion to know more about each of these options (https://fairseq.readthedocs.io/en/latest/command_line_tools.html)\n\n\n# some notable args:\n# --max-update=1000     -> for this example, to demonstrate how to finetune we are only training for 1000 steps. You should increase this when finetuning\n# --arch=transformer_4x -> we use a custom transformer model and name it transformer_4x (4 times the parameter size of transformer  base)\n# --user_dir            -> we define the custom transformer arch in model_configs folder and pass it as an argument to user_dir for fairseq to register this architechture\n# --lr                  -> learning rate. From our limited experiments, we find that lower learning rates like 3e-5 works best for finetuning.\n# --restore-file        -> reload the pretrained checkpoint and start training from here (change this path for indic-en. Currently its is set to en-indic)\n# --reset-*             -> reset and not use lr scheduler, dataloader, optimizer etc of the older checkpoint\n# --max_tokns           -> this is max tokens per batch\n\n\n!( fairseq-train ../../drive/MyDrive/Dravidian_Dataset_Full/final_bin \\\n--max-source-positions=1320 \\\n--max-target-positions=1320 \\\n--max-epoch=6 \\\n--share-all-embeddings \\\n--arch=transformer_4x \\\n--criterion=label_smoothed_cross_entropy \\\n--source-lang=SRC \\\n--target-lang=TGT \\\n--label-smoothing=0.1 \\\n--optimizer adam \\\n--adam-betas \"(0.9, 0.98)\" \\\n--clip-norm 1.0 \\\n--warmup-init-lr 1e-07 \\\n--warmup-updates 1000 \\\n--dropout 0.2 \\\n--lr-scheduler=inverse_sqrt \\\n--lr 3e-5 \\\n--tensorboard-logdir ../../../tmp/tensorboard-wandb \\\n--save-dir ../../drive/MyDrive/Dravidian_Dataset_Full/model \\\n--skip-invalid-size-inputs-valid-test \\\n--fp16 \\\n--user-dir model_configs \\\n--update-freq=2 \\\n--distributed-world-size 1 \\\n--max-tokens 1568 \\\n--eval-bleu \\\n--eval-bleu-args '{\"beam\": 5, \"max_len_a\": 1.2, \"max_len_b\": 10}' \\\n--eval-bleu-detok moses \\\n--eval-bleu-remove-bpe \\\n--eval-bleu-print-samples \\\n--best-checkpoint-metric bleu \\\n--maximize-best-checkpoint-metric \\\n--no-epoch-checkpoints \\\n--restore-file ../../drive/MyDrive/Dravidian_Dataset_Full/model/checkpoint_best.pt \\\n--wandb-project \"kn-ml backtranslation_strip final pls\" \\\n--reset-lr-scheduler \\\n--reset-meters \\\n--reset-dataloader \\\n--reset-optimizer)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T15:17:39.273113Z","iopub.execute_input":"2022-02-09T15:17:39.273395Z","iopub.status.idle":"2022-02-09T18:28:09.216445Z","shell.execute_reply.started":"2022-02-09T15:17:39.273358Z","shell.execute_reply":"2022-02-09T18:28:09.215639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..\n!mkdir data\n%cd data","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:28:09.219159Z","iopub.execute_input":"2022-02-09T18:28:09.219484Z","iopub.status.idle":"2022-02-09T18:28:09.963416Z","shell.execute_reply.started":"2022-02-09T18:28:09.219442Z","shell.execute_reply":"2022-02-09T18:28:09.962575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1P7ZTatFxoLxjr80fE2ogO7aj0xKdesij --folder","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:36:23.748394Z","iopub.execute_input":"2022-02-09T18:36:23.748682Z","iopub.status.idle":"2022-02-09T18:36:32.023385Z","shell.execute_reply.started":"2022-02-09T18:36:23.748652Z","shell.execute_reply":"2022-02-09T18:36:32.022572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ..\n%cd indicTrans","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:39:20.301246Z","iopub.execute_input":"2022-02-09T18:39:20.301780Z","iopub.status.idle":"2022-02-09T18:39:20.315328Z","shell.execute_reply.started":"2022-02-09T18:39:20.301742Z","shell.execute_reply":"2022-02-09T18:39:20.314279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# To test the models after training, you can use joint_translate.sh\n# joint_translate takes src_file, output_fname, src_lang, tgt_lang, model_folder as inputs\n# src_file -> input text file to be translated\n# output_fname -> name of the output file (will get created) containing the model predictions\n# src_lang -> source lang code of the input text ( in this case we are using en-indic model and hence src_lang would be 'en')\n# tgt_lang -> target lang code of the input text ( tgt lang for en-indic model would be any of the 11 indic langs we trained on:\n#              as, bn, hi, gu, kn, ml, mr, or, pa, ta, te)\n# supported languages are:\n#              as - assamese, bn - bengali, gu - gujarathi, hi - hindi, kn - kannada, \n#              ml - malayalam, mr - marathi, or - oriya, pa - punjabi, ta - tamil, te - telugu\n\n# model_dir -> the directory containing the model and the vocab files\n\n# Note: if the translation is taking a lot of time, please tune the buffer_size and batch_size parameter for fairseq-interactive defined inside this joint_translate script\n# exp_dir= ../data/kn-ml/dev/dev.kn\n# download_dir= ../m2m\n\n# here we are translating the english sentences to hindi\n!bash joint_translate.sh ../data/kn-ta/dev/dev.kn ../data/kn-ta/kn_ta_outputs.txt 'kn' 'ta' ../../drive/MyDrive/Dravidian_Dataset_Full","metadata":{"id":"tpPsT1e7vuO9","outputId":"2ef8ab57-b906-4c01-a058-0713a6e42703","execution":{"iopub.status.busy":"2022-02-09T18:39:27.739782Z","iopub.execute_input":"2022-02-09T18:39:27.740365Z","iopub.status.idle":"2022-02-09T18:41:25.762280Z","shell.execute_reply.started":"2022-02-09T18:39:27.740324Z","shell.execute_reply":"2022-02-09T18:41:25.761440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat ../data/kn-ta/kn_ta_outputs.txt","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:41:25.765762Z","iopub.execute_input":"2022-02-09T18:41:25.766352Z","iopub.status.idle":"2022-02-09T18:41:26.524694Z","shell.execute_reply.started":"2022-02-09T18:41:25.766318Z","shell.execute_reply":"2022-02-09T18:41:26.503499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"id":"ANjkcuRpNbOz","outputId":"736612ca-942d-4a43-cc42-d6beb2841d94","execution":{"iopub.status.busy":"2022-02-09T18:41:26.531365Z","iopub.execute_input":"2022-02-09T18:41:26.531640Z","iopub.status.idle":"2022-02-09T18:41:27.292637Z","shell.execute_reply.started":"2022-02-09T18:41:26.531601Z","shell.execute_reply":"2022-02-09T18:41:27.291752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to compute bleu scores for the predicitions with a reference file, use the following command\n# arguments:\n# pred_fname: file that contains model predictions\n# ref_fname: file that contains references\n# src_lang and tgt_lang : the source and target language\n\n!bash compute_bleu.sh ../data/kn-ta/kn_ta_outputs.txt ../data/kn-ta/dev/dev.ta 'kn' 'ta'","metadata":{"id":"bPqneByPxilN","outputId":"5614e9f0-4ae7-42fe-8467-70e3b3a73eaf","execution":{"iopub.status.busy":"2022-02-09T18:41:27.295135Z","iopub.execute_input":"2022-02-09T18:41:27.295445Z","iopub.status.idle":"2022-02-09T18:41:30.411501Z","shell.execute_reply.started":"2022-02-09T18:41:27.295407Z","shell.execute_reply":"2022-02-09T18:41:30.410716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! fairseq-generate ../data/kn-ml \\\n# --path ../../drive/MyDrive/Dravidian_Dataset_Full/checkpoint1.pt \\\n# --batch-size 64 \\\n# --beam 5 \\\n# --seed 1 \\\n# --scoring bleu \\\n# --wandb-project \"kn-ml fairseq\"","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:29:36.914608Z","iopub.execute_input":"2022-02-09T18:29:36.914883Z","iopub.status.idle":"2022-02-09T18:29:36.920030Z","shell.execute_reply.started":"2022-02-09T18:29:36.914845Z","shell.execute_reply":"2022-02-09T18:29:36.918694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted = open(\"../data/kn-ta/kn_ta_outputs.txt\")\nactual= open(\"../data/kn-ta/dev/dev.ta\")\np = predicted.readlines()\na = actual.readlines()\ncount=0\nlmt=10\nfor x,y in zip(p,a):\n    print('----------------------------------------------',count+1,'-----------------------------------')\n    print('A: ',y)\n    print('P: ',x)\n    count+=1\n    if count==lmt:\n        break","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:41:30.415867Z","iopub.execute_input":"2022-02-09T18:41:30.416356Z","iopub.status.idle":"2022-02-09T18:41:30.447024Z","shell.execute_reply.started":"2022-02-09T18:41:30.416322Z","shell.execute_reply":"2022-02-09T18:41:30.446399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cat ../data/kn-ml/kn_ml_outputs.txt","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:29:37.117361Z","iopub.status.idle":"2022-02-09T18:29:37.117679Z","shell.execute_reply.started":"2022-02-09T18:29:37.117506Z","shell.execute_reply":"2022-02-09T18:29:37.117527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from indicnlp.tokenize.indic_tokenize import trivial_tokenize\nfrom indicnlp.normalize.indic_normalize import IndicNormalizerFactory\nfrom indicnlp.tokenize import sentence_tokenize\nimport re\n\nINDIC = [\"as\", \"bn\", \"gu\", \"hi\", \"kn\", \"ml\", \"mr\", \"or\", \"pa\", \"ta\", \"te\"]\n\ndef split_sentences(paragraph, language):\n    pattern=re.compile(r'\\s*[.]\\s*')\n    matches=pattern.split(paragraph)\n    final=[]\n    for match in matches:\n        if len(match)==0:\n            continue\n        if len(match)>200:\n            m=re.compile(r'\\s*[,]\\s*').split(paragraph)\n            lst=[]\n            s=\"\"\n            for x in m:\n                x+=\", \"\n                if x==\"\":\n                    continue\n                if len(s+x)<200:\n                    s+=x\n                else:\n                    lst.append(s)\n                    s=x\n            lst.append(s[:-2])\n            final.extend(lst)\n        else:\n            final.append(match)\n    return final\n\n\nlang = 'kn'\ninput_path = '../data/kn-ta/dev/dev.kn'\noutput_path = '../data/kn-ta/kn_strip.txt'\n\ncount=-1\ndic={}\nwith open(input_path, 'r', encoding='utf-8') as in_fp,\\\n\t open(output_path, 'w', encoding='utf-8') as out_fp:\n    for line in in_fp.readlines():\n        count+=1\n        sent = line.rstrip('\\n')\n        if len(sent)>200:\n            sent_list=split_sentences(sent,'kn')\n            dic[str(count)]=len(sent_list)\n            for lol in sent_list:\n                out_fp.write(lol)\n                out_fp.write('\\n')\n        else:\n            out_fp.write(sent)\n            out_fp.write('\\n')\nprint(dic)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:44:00.741186Z","iopub.execute_input":"2022-02-09T18:44:00.741776Z","iopub.status.idle":"2022-02-09T18:44:00.777039Z","shell.execute_reply.started":"2022-02-09T18:44:00.741738Z","shell.execute_reply":"2022-02-09T18:44:00.776189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!bash joint_translate.sh ../data/kn-ta/kn_strip.txt ../data/kn-ta/kn_ta_strip_outputs.txt 'kn' 'ta' ../../drive/MyDrive/Dravidian_Dataset_Full","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:44:08.039440Z","iopub.execute_input":"2022-02-09T18:44:08.039738Z","iopub.status.idle":"2022-02-09T18:46:04.587647Z","shell.execute_reply.started":"2022-02-09T18:44:08.039707Z","shell.execute_reply":"2022-02-09T18:46:04.586758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from indicnlp.tokenize.indic_tokenize import trivial_tokenize\nfrom indicnlp.normalize.indic_normalize import IndicNormalizerFactory\nfrom indicnlp.tokenize import sentence_tokenize\nimport re\n\nlang = 'ta'\noutput_path = '../data/kn-ta/ta_combined.txt'\ninput_path = '../data/kn-ta/kn_ta_strip_outputs.txt'\n\ncount=-1 \nwith open(input_path, 'r', encoding='utf-8') as in_fp,\\\n\t open(output_path, 'w', encoding='utf-8') as out_fp:\n    line=in_fp.readlines()\n    i=0\n    while i < len(line):\n        if str(i) in dic.keys():\n            for j in range(dic[str(i)]):\n                sent = line[i].rstrip('\\n')\n                out_fp.write(sent)\n                out_fp.write(\" \")\n                i+=1\n            out_fp.write('\\n')\n        else:\n            sent = line[i].rstrip('\\n')\n            out_fp.write(sent)\n            out_fp.write('\\n')\n            i+=1","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:46:04.590071Z","iopub.execute_input":"2022-02-09T18:46:04.590380Z","iopub.status.idle":"2022-02-09T18:46:04.606031Z","shell.execute_reply.started":"2022-02-09T18:46:04.590341Z","shell.execute_reply":"2022-02-09T18:46:04.605182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = open(\"../data/kn-ta/ta_combined.txt\",\"r\")\nCounter = 0\n  \n# Reading from file\nContent = file.read()\nCoList = Content.split(\"\\n\")\n  \nfor i in CoList:\n    if i:\n        Counter += 1\nprint(\"This is the number of lines in the file\")\nprint(Counter)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:46:04.608576Z","iopub.execute_input":"2022-02-09T18:46:04.609472Z","iopub.status.idle":"2022-02-09T18:46:04.623566Z","shell.execute_reply.started":"2022-02-09T18:46:04.609433Z","shell.execute_reply":"2022-02-09T18:46:04.622848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!bash compute_bleu.sh ../data/kn-ta/ta_combined.txt ../data/kn-ta/dev/dev.ta 'kn' 'ta'","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:46:04.626135Z","iopub.execute_input":"2022-02-09T18:46:04.626493Z","iopub.status.idle":"2022-02-09T18:46:07.829227Z","shell.execute_reply.started":"2022-02-09T18:46:04.626441Z","shell.execute_reply":"2022-02-09T18:46:07.828353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !cat ../data/kn-ml/kn_ml_strip_outputs.txt","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:29:37.138009Z","iopub.status.idle":"2022-02-09T18:29:37.138436Z","shell.execute_reply.started":"2022-02-09T18:29:37.138194Z","shell.execute_reply":"2022-02-09T18:29:37.138236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cat ../data/kn-ml/ml_combined.txt","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:29:37.139804Z","iopub.status.idle":"2022-02-09T18:29:37.140704Z","shell.execute_reply.started":"2022-02-09T18:29:37.140442Z","shell.execute_reply":"2022-02-09T18:29:37.140469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from indicnlp.tokenize.indic_tokenize import trivial_tokenize\nfrom indicnlp.normalize.indic_normalize import IndicNormalizerFactory\nfrom indicnlp.tokenize import sentence_tokenize\nimport re\n\nINDIC = [\"as\", \"bn\", \"gu\", \"hi\", \"kn\", \"ml\", \"mr\", \"or\", \"pa\", \"ta\", \"te\"]\n\ndef split_sentences(paragraph, language):\n    pattern=re.compile(r'\\s*[.]\\s*')\n    matches=pattern.split(paragraph)\n    final=[]\n    for match in matches:\n        if len(match)==0:\n            continue\n        if len(match)>200:\n            m=re.compile(r'\\s*[,]\\s*').split(paragraph)\n            lst=[]\n            s=\"\"\n            for x in m:\n                x+=\", \"\n                if x==\"\":\n                    continue\n                if len(s+x)<200:\n                    s+=x\n                else:\n                    lst.append(s)\n                    s=x\n            lst.append(s[:-2])\n            final.extend(lst)\n        else:\n            final.append(match)\n    return final\n\n\nlang = 'kn'\ninput_path = '../data/kn-ta/test/test.kn'\noutput_path = '../data/kn-ta/test_strip.txt'\n\ncount=-1\ndic={}\nwith open(input_path, 'r', encoding='utf-8') as in_fp,\\\n\t open(output_path, 'w', encoding='utf-8') as out_fp:\n    for line in in_fp.readlines():\n        count+=1\n        sent = line.rstrip('\\n')\n        if len(sent)>200:\n            sent_list=split_sentences(sent,'kn')\n            dic[str(count)]=len(sent_list)\n            for lol in sent_list:\n                out_fp.write(lol)\n                out_fp.write('\\n')\n        else:\n            out_fp.write(sent)\n            out_fp.write('\\n')\nprint(dic)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:46:07.831420Z","iopub.execute_input":"2022-02-09T18:46:07.832355Z","iopub.status.idle":"2022-02-09T18:46:07.987359Z","shell.execute_reply.started":"2022-02-09T18:46:07.832312Z","shell.execute_reply":"2022-02-09T18:46:07.986277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!bash joint_translate.sh ../data/kn-ta/test_strip.txt ../data/kn-ta/test_strip_outputs.txt 'kn' 'ta' ../../drive/MyDrive/Dravidian_Dataset_Full","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:46:07.988683Z","iopub.execute_input":"2022-02-09T18:46:07.988915Z","iopub.status.idle":"2022-02-09T18:47:53.301004Z","shell.execute_reply.started":"2022-02-09T18:46:07.988883Z","shell.execute_reply":"2022-02-09T18:47:53.299996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from indicnlp.tokenize.indic_tokenize import trivial_tokenize\nfrom indicnlp.normalize.indic_normalize import IndicNormalizerFactory\nfrom indicnlp.tokenize import sentence_tokenize\nimport re\n\nlang = 'ta'\noutput_path = '../data/kn-ta/ta_test_pred.txt'\ninput_path = '../data/kn-ta/test_strip_outputs.txt'\n\ncount=-1 \nwith open(input_path, 'r', encoding='utf-8') as in_fp,\\\n\t open(output_path, 'w', encoding='utf-8') as out_fp:\n    line=in_fp.readlines()\n    i=0\n    while i < len(line):\n        if str(i) in dic.keys():\n            for j in range(dic[str(i)]):\n                sent = line[i].rstrip('\\n')\n                out_fp.write(sent)\n                out_fp.write(\" \")\n                i+=1\n            out_fp.write('\\n')\n        else:\n            sent = line[i].rstrip('\\n')\n            out_fp.write(sent)\n            out_fp.write('\\n')\n            i+=1","metadata":{"execution":{"iopub.status.busy":"2022-02-09T18:47:53.303970Z","iopub.execute_input":"2022-02-09T18:47:53.304291Z","iopub.status.idle":"2022-02-09T18:47:53.324988Z","shell.execute_reply.started":"2022-02-09T18:47:53.304251Z","shell.execute_reply":"2022-02-09T18:47:53.324130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat ../data/kn-ta/ta_test_pred.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}